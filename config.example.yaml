# Turbo-Heartbeat Configuration
# Generated by Siegfried on 2026-02-07
# DO NOT EDIT MANUALLY — managed by assistant
#
# Uses OpenAI-compatible /v1/chat/completions API.
# Works with: Ollama, LM Studio, llama.cpp, vLLM, LocalAI, Jan,
#             Groq, Mistral, OpenRouter, OpenAI, and any compatible endpoint.

version: "1.0"
profile: "A"

# Triage Model — just a URL, a key, and a model name
api_base: "http://localhost:11434/v1"
api_key: "ollama"
model: "glm-4.7-flash"
# Set true for thinking models (GLM, Qwen-thinking, DeepSeek-R1) on local engines
# Adds "think":false to suppress wasted reasoning tokens
# Cloud providers (Groq, OpenAI) reject this field — leave false for them
disable_thinking: true

# Timing
interval_seconds: 30
cooldown_seconds: 300
max_per_hour: 6

# Quiet Hours
quiet_start: "23:00"
quiet_end: "08:00"
timezone: "Europe/Berlin"

# Signal Collectors
signals_email: true
signals_calendar: true
signals_system: true

# Credentials
email_credentials: "~/.config/your-app/email_credentials.json"

# Critical Notification
notify_channel: "telegram"
notify_email: "user@example.com"
smtp_host: "smtp.strato.de"
smtp_port: 465
smtp_user: "assistant@example.com"
smtp_pass: ""
smtp_from: "assistant@example.com"

# Gateway (for escalation)
gateway_port: 18789
gateway_token: "YOUR_GATEWAY_TOKEN"

# Statistics
stats_enabled: true
stats_retention_days: 30
